Dictionaries
------------
- two letter words and definitions, for example.
- "word" is a `key` that addresses the definition 
- "definition" is a `value`
- insert a definition into a dictionary
- function hashCode() maps each word (`key`) to a unique integer in the range 0-625 (26*26), then use that integer to lookup the word in the array

example:
-------
public class Word {
  public static final int LETTERS = 26,
                          WORDS = LETTERS * LETTERS;
  private String word;

  public int hashCode() {
    return LETTERS * (word.charAt(0) - 'a') + (word.charAt(1) - 'a');
  }
}

public class WordDictionary {
  private Definition[] defTable = new Definition[Word.WORDS];

  public void insert(Word w, Definition d) {
    defTable[w.hashCode()] = d;
  }

  Definition find(Word w) {
    return defTable[w.hashCode()];
  }
}

* how to store dictionary with the entire English language? 


Hash Tables
-----------
operations to support:
- insert()
- remove()
- find()

n: number of keys stored in the table
N: number of buckets, N is a big larger than n
A hash table maps huge set of possible keys into N buckets by applying a compression function to each hash code.

compression function example:
h(hashCode) = hashCode mod N

- hashCodes are often negative. (mod N => 0...N-1) //TODO: exact behavior of mod in Java?
- collision: several keys hash to the same bucket, if h(hashCode1) == h(hashCode2)

Handling collisions? 
`Chaining`: each bucket stores a linked list of entries, called a *chain*, but you have to store the word and the definition 
  - entry = (key, value)

defTable[] ---> [ -, -, -, ... ]
each item in defTable's array points to one or more buckets that are stored

``` G & T ```

public Entry insert(key, value) {
  - compute the key's hash code
  - compress the hash code so it fits into the table
  - insert the entry into bucket's chain
  - returns entry
}

public Entry find(key) {
  - compute key's hash code and compress
  - find which bucket it is in and search chain for entry with given key
  - if entry found, return; else null
}

public Entry remove(key) {
  - hash the key
  - search the chain
  - remove from chain if found
  - return entry
}


what if you want to have multiple copies of the same key? 
- you can insert both and return one of them arbitrarily (G&T also has a findAll operation)
- or you can do replacement

Performance
-----------
- "load factor" of a hash table n / N
if load factor stays low and hash code & compression functions are "good," and no duplicate keys, then the linked list / chain will stay short. => each operation takes constant time. Omega(1) time

if load factor gets Big, where (n >> N), then the chains will get as long as n/N, so each operation will run in linear time, theta(n) time  


Hash codes & compression functions
----------------------------------
key ----> hashcode ----> [0, N-1] (via compression function)

Ideal: map every key to a random bucket, with each bucket being equally likely

Bad compression function: 
  Suppose keys are ints. 
  hashCode(i) = i.  // hashCode is just itself, the int. 
  Compression fn h(hashCode) = hashCode mod N, where N = 10,000

  Suppose keys are divisible by 4. h() is divisible by 4 too. => 3/4 of our buckets are wasted

  ** Same compression fn better if N is prime ** 

Better compression function:
  h(hashCode) == (( a * hashCode + b) mod p) mod N) 
  
  where p is some large prime, and a & b are positive integers
  p >> N
  mod p will scramble the bits really well and N doesn't need to be prime anymore
  mod N will make it fit into your table
  (Read 9.2.4 of G & T)


Hash codes
----------
if your key is an integer, that key can just be it's own hash code

good hash code for Strings:

private static int hashCode(String key) {
  int hashVal = 0;
  for (int i=0; i< key.length(); i++) {
    hashVal += (127 * hashVal + key.charAt(i)) % 16908799;
  }
  return hashVal;

}

bad hash codes on Words... 
there are systematic biases in words
1. Sum ASCII values of characters.
    Rarely exceed 500. So you'll end up with most of the words bunched up in 500 buckets.
    Anagrams will always collide in this scheme: "pat", "apt", "tap" for example
2. First 3 letters of a word with 26^3 buckets
    Systematic bias in English, i.e. lots of "pre.." words, but no words that begin with "xzq"
3. Suppose you take the good hash function and chage the prime modulus to 127.
    => (127 * hashVal) % 127 = 0, so no good. 
    If the numbers you're multiplying / modulo'ing has a factor in common, => bad
    If your application creates keys that are only divisble by 7, for example, then 6/7th of your buckets don't get used :( 


Resizing the Hash Table
-----------------------
- If load factor n/N too large, lose O(1) time
- Enlarge hash table when load factor > c, typically 0.75
- Allocate a new array (at least 2 times as large as the old hash table)
- Walk through the old array, find all the entries it stores and hash them again. 

Option: Shrinking hash tables (e.g. when n/N < 0.25) => to free up memory

"Probing" - see G&T

Applications
------------
Transposition tables: Speed Game Trees
- Use a hash table to remember all the boards that we encountered and save the board and the score
- Some grids can be reached through many sequences of moves
- key is the grid, value is the score for that grid


